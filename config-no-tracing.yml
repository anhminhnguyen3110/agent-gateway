# Config without tracing (use when Jaeger is not running)
# Metrics and logging will still work!

binds:
- port: 3000
  listeners:
  - routes:
    # LLM route - OpenRouter with Llama 3.3
    - matches:
      - path:
          pathPrefix: /v1/chat/completions
      backends:
      - ai:
          name: openrouter
          hostOverride: openrouter.ai:443
          provider:
            openAI:
              model: meta-llama/llama-3.3-70b-instruct:free
          routes:
            /v1/chat/completions: completions
      policies:
        urlRewrite:
          authority:
            full: openrouter.ai
          path:
            full: /api/v1/chat/completions
        backendTLS: {}
        backendAuth:
          key: $OPENROUTER_API_KEY
    # MCP route
    - matches:
      - path:
          pathPrefix: /mcp
      backends:
      - mcp:
          targets:
          - name: everything
            stdio:
              cmd: npx
              args:
              - '@modelcontextprotocol/server-everything'
      policies:
        extAuthz:
          host: localhost:9000
        cors:
          allowOrigins:
          - '*'
          allowHeaders:
          - mcp-protocol-version
          - content-type
          - cache-control
          - '*'
          - authorization